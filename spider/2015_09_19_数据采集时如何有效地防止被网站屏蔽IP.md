### 数据采集时如何有效地防止被网站屏蔽IP

发布时间：2015-09-19 来源：未知 浏览：

------

​        现在越来越多的网站开始注意保护自己的数据（在这一点上国外网站做的要比国内早），通过各种策略来反抗异常的爬虫。其中最常见的策略是限制客户端IP的访问频率，通常表现为当爬虫客户端访问网站速度过快时，网站会在一段时间内返回403、503之类的错误（例如谷歌、亚马逊）或返回验证码页面（例如大众点评网、去哪儿网），不排除个别BT的网站会永久封锁你IP的可能，比如nmlsconsumeraccess.org，但不在本文讨论范围之内。

​        如果你是个阅站无数的虫师（爬虫开发者），你一定碰到过我说的情况（IP被网站屏蔽掉），你是如何应对的呢？在我们以往的项目经历中，遇到的60%以上的网站都使用了类似的策略（简单的网站客户也不会找我们采集）。下面是我们的一些经验分享：

**1）	测试安全间隔。**

​        测试的目的就是得到网站允许的最大访问频率是多少，确定一个合理的访问时间间隔。方法是：先使用一个较大的间隔（例如30秒）去访问网站（可以自己写程序实现，也可以借助类似iMacros的浏览器自动化插件），如果不会被屏蔽就减少间隔时间，重复上述步骤直到IP被屏蔽。假设间隔3秒正常，间隔2秒时被屏蔽了，我们就能大概估计出网站允许的最大访问频率限制为“1次/3秒”。

**2）	制定控制策略。**

​        如果我们使用“1次/大于3秒”的频率去访问网站就是安全的（当然这个频率越小越安全），根据我们的经验，大多网站使用“大于3秒”的时间间隔访问是不会触发网站的屏蔽策略（我们的建议间隔值：5秒）。

​        在程序中的实现方法：对于同一个IP，在下载页面之前判断与上次访问间隔的时间是否超过5秒了，如果没有就sleep，直到超过5秒才能发出下一个请求。

**3）	用多线程+HTTP代理提速。**

​        如果我们采用5秒的时间间隔意味着每分钟我们只能完成12次的访问（HTTP请求），一天也仅仅能完成不到2万次的下载（3600 * 24  / 5 = 17280）。这个速度对于小规模的网站还能接受，但对于拥有上百万甚至千万页面的网站来说，这个速度实在是太慢了。以大众点评网为例，1500万页，照这个速度需要2年零4个月才能完成，太可怕了。

​        而我们采集一次大众点评网仅需要15天左右，我们是怎么做到的呢？ 就是通过多线程+ HTTP代理。用过HTTP代理的虫师都知道当我们通过高匿名HTTP代理发出一个请求，目标网站只能检测到HTTP代理的IP，而无法检测到源IP，也无法知道你在使用代理，对目标网站来说这个请求是来自于另外一个访客（与你无关）。假设我们拥有100个稳定高匿的HTTP代理，仍然在同IP间隔5秒的前提下，理论上每天能达到的下载量是170万！

​        在程序中的实现方法：开启100个线程，每个线程固定地使用一个HTTP代理，每个线程处理不同的采集任务，每个线程内控制访问网站的速度。由于数据提取是纯计算操作多线程并不能加速（关于这一点鲲鹏数据的技术人员之前做过详细的分析，详见这里<http://www.site-digger.com/html/articles/20131019/69.html>），12核CPU环境下，实际每天的采集量能达到100万左右（每个页面提取20个字段左右）。

 

**FAQ：**

**问题一：我从网上找了很多免费代理用在爬虫里，但采集还是大量出现HTTP 403错误，这是为什么？**

​        需要注意的是，并非所有的HTTP代理都适合于Web数据采集。网上免费的HTTP代理大多是不稳定的透明代理（俗称“野代理”），不能有效的用于Web数据采集。事实上，只有高匿稳定的HTTP代理才能有效的应用于爬虫中，关于这点，我们在之前的文章里也做了详细的介绍（<http://www.site-digger.com/html/articles/20130114/50.html>）。

**问题二：有的网站限制一个IP一天只能访问1000次，怎么破？**

​        答案也是使用HTTP代理，100个HTTP代理每天就能实现10万次的下载。另外有些网站在判断客户端IP上存在逻辑错误，比如为了限制HTTP代理访问频率就直接使用X-Forwarded-For值做为客户端IP，对于这种情况,我们可以伪造虚假的IP地址放到X-Forwarded-For中来绕过。

**问题三：我之前没用过HTTP代理，在程序中怎么使用呢？**

​        可以参考我们编写的文档 <http://www.site-digger.com/uploads/how_to_use_http_proxy.pdf>

**问题四：有没有什么工具可以帮助测试代理的可用性？**

​        我们编写了一个在线工具，网址是<http://proxies.site-digger.com/proxy-test/>，希望对你有帮助。